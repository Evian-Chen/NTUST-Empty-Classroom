name: Daily Crawler

on:
  schedule:
    - cron: '0 21 * * 0-4'   # 每天 21:00 UTC = 台北 05:00

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip3 install -r backend/requirements.txt
          # 安裝 Chrome
          sudo apt-get update
          sudo apt-get install -y wget gnupg unzip
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          # webdriver-manager 會自動下載並管理 ChromeDriver
      
      - name: Check environment
        run: |
          echo "Environment Check:"
          echo "Python version: $(python3 --version)"
          echo "Chrome version: $(google-chrome --version)"
          echo "Current directory: $(pwd)"
          echo "Available files: $(ls -la backend/crawler/)"
          
      - name: Run crawler
        env:
          TZ: Asia/Taipei
          MONGO_URI: ${{ secrets.MONGO_URI }}
        run: |
          cd backend/crawler
          echo "Starting Daily Crawler..."
          echo "Current time: $(date)"
          echo "Timezone: $TZ"
          
          # 運行爬蟲並捕獲輸出
          python3 dailyCrawler.py 2>&1 | tee crawler_output.log
          
          echo ""
          echo "Crawler execution completed!"
          echo "Exit code: $?"
          
          # 顯示日誌摘要
          if [ -f crawler_output.log ]; then
            echo ""
            echo "Output Summary:"
            echo "=================="
            cat crawler_output.log
            echo "=================="
            
            # 檢查是否有錯誤
            if grep -i "error\|exception\|failed" crawler_output.log > /dev/null; then
              echo "Errors detected in crawler output!"
              exit 1
            else
              echo "Crawler completed successfully!"
            fi
          fi

      - name: Upload crawler logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: daily-crawler-logs
          path: backend/crawler/crawler_output.log
          retention-days: 7
